{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_LM_char_based.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0zK4haIjTLhe"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import numpy\n",
        "import string\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "string.punctuation = string.punctuation + '“' + '”' +'-' + '’' + '‘' + '—'\n",
        "string.punctuation = string.punctuation.replace('.', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2ly5AxBTrlO",
        "outputId": "0e46699d-1c53-4571-af4b-08c8294b6720"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to text file\n",
        "doc_path = \"drive/MyDrive/Newcastle University/Deep Learning/Data/61262-0.txt\""
      ],
      "metadata": {
        "id": "6zhN_JxSTRrv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the data and preprocesses data and stores corpus in raw_text\n",
        "raw_text = open(doc_path, encoding = 'utf8').read()\n",
        "\n",
        "file_nl_removed = \"\"\n",
        "for line in raw_text:\n",
        "  line_nl_removed = line.replace(\"\\n\", \" \")           #removes newlines\n",
        "  file_nl_removed += line_nl_removed\n",
        "\n",
        "file_p = \"\".join([char for char in file_nl_removed if char not in string.punctuation])   #removes all special characters\n",
        "sents = nltk.sent_tokenize(file_p)\n",
        "print(\"The number of sentences is\", len(sents)) #prints the number of sentences\n",
        "\n",
        "string.punctuation = string.punctuation + '.'\n",
        "file_q = \"\".join([char for char in file_p if char not in string.punctuation])   #removes even periods.\n",
        "words = nltk.word_tokenize(file_q)\n",
        "print(\"The number of tokens is\", len(words)) #prints the number of tokens\n",
        "\n",
        "average_tokens = round(len(words)/len(sents))\n",
        "print(\"The average number of tokens per sentence is\", average_tokens) #prints the average number of tokens per sentence\n",
        "\n",
        "unique_tokens = set(words)\n",
        "print(\"The number of unique tokens are\", len(unique_tokens)) #prints the number of unique tokens\n",
        "\n",
        "preprocessed_text = file_p.lower()       #converts corpus into lowercase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFEKRjQ_TWix",
        "outputId": "66dc2c24-a64b-412f-d6d6-f8ff044bf5f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of sentences is 3945\n",
            "The number of tokens is 55708\n",
            "The average number of tokens per sentence is 14\n",
            "The number of unique tokens are 7326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_text[1500:1638])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht5egZbyTerb",
        "outputId": "2c21fa9b-e06b-4fb4-abda-754cb25022ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "appearance of mr. davenheim    x the adventure of the italian nobleman    xi the case of the missing will       poirot investigates       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_text[1638:2000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV31r4dbTuKM",
        "outputId": "53ba2773-3904-49ae-e159-7ab7585e652e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "poirot investigates     i     the adventure of the western star  i was standing at the window of poirots rooms looking out idly on the street below.  thats queer i ejaculated suddenly beneath my breath.  what is mon ami asked poirot placidly from the depths of his comfortable chair.  deduce poirot from the following facts here is a young lady richly dressedfas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_text[-18700:-18640])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH7YreXGTuM1",
        "outputId": "1a6f352b-4aa2-4e1c-d4d4-ca3da0c3ef8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h wonderwhat old andrew marsh would have thought     the end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing disclaimer and other non novel text\n",
        "preprocessed_text = preprocessed_text[1638:-18640]"
      ],
      "metadata": {
        "id": "528XsiBvTuPs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(preprocessed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOh2jZgITuSE",
        "outputId": "32aa5430-4246-4aed-a811-b091118b3ed5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '£',\n",
              " 'à',\n",
              " 'â',\n",
              " 'æ',\n",
              " 'ç',\n",
              " 'è',\n",
              " 'é',\n",
              " 'ê',\n",
              " 'ô',\n",
              " '•'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses the preprocessed data and create raw_text\n",
        "raw_text = preprocessed_text   #periods have not been removed for better results\n",
        "\n",
        "# creates mapping of unique characters to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "3CGm7H7iTuUp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the total characters and character vocab size\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print(\"The number of total characters are\", n_chars)\n",
        "print(\"\\nThe character vocab size is\", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh1S_cR4TuWx",
        "outputId": "ada331e8-cf58-4aac-d83f-2b88daada658"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of total characters are 285205\n",
            "\n",
            "The character vocab size is 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepares dataset where the input is sequence of 100 characters and target is next character.\n",
        "seq_length = 100\n",
        "\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE6pAKuITudz",
        "outputId": "f3c805f4-6d34-4924-97c3-c32e6cec5dbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  285105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshapes X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# one hot encodes the output variable\n",
        "y = to_categorical(dataY)"
      ],
      "metadata": {
        "id": "AKwSoUjFTug2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim =100\n",
        "max_length =100"
      ],
      "metadata": {
        "id": "3_zhl25bTujg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(n_vocab, embedding_dim, input_length=max_length))\n",
        "model1.add(LSTM(256, input_shape=(X.shape[1], embedding_dim),return_sequences=True))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(LSTM(256))\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "id": "e4Mlm8fiTumF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp = ModelCheckpoint('drive/MyDrive/Newcastle University/Deep Learning/Models/DL_LM_CB.h5', monitor='val_loss')"
      ],
      "metadata": {
        "id": "XOzwkBb7ZY76"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "41wpjx1YYwsE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s52ZfsUrYviV",
        "outputId": "739d1e8f-00a0-4f09-b67a-1b41dac601a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          4800      \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100, 256)          365568    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 48)                12336     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 908,016\n",
            "Trainable params: 908,016\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X, y, epochs = 20, batch_size=64, callbacks=cp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltobuCc6Yy6W",
        "outputId": "c7ec4671-b547-47a1-844b-dc7bc2f44169"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4455/4455 [==============================] - 109s 24ms/step - loss: 1.9707 - accuracy: 0.4094\n",
            "Epoch 2/20\n",
            "4455/4455 [==============================] - 106s 24ms/step - loss: 1.5577 - accuracy: 0.5233\n",
            "Epoch 3/20\n",
            "4455/4455 [==============================] - 105s 24ms/step - loss: 1.4313 - accuracy: 0.5589\n",
            "Epoch 4/20\n",
            "4455/4455 [==============================] - 105s 24ms/step - loss: 1.3626 - accuracy: 0.5777\n",
            "Epoch 5/20\n",
            "4455/4455 [==============================] - 105s 24ms/step - loss: 1.3195 - accuracy: 0.5889\n",
            "Epoch 6/20\n",
            "4455/4455 [==============================] - 105s 24ms/step - loss: 1.2867 - accuracy: 0.5975\n",
            "Epoch 7/20\n",
            "4455/4455 [==============================] - 105s 24ms/step - loss: 1.2588 - accuracy: 0.6039\n",
            "Epoch 8/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.2398 - accuracy: 0.6100\n",
            "Epoch 9/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.2236 - accuracy: 0.6141\n",
            "Epoch 10/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.2087 - accuracy: 0.6179\n",
            "Epoch 11/20\n",
            "4455/4455 [==============================] - 103s 23ms/step - loss: 1.1972 - accuracy: 0.6214\n",
            "Epoch 12/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.1885 - accuracy: 0.6240\n",
            "Epoch 13/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.1804 - accuracy: 0.6251\n",
            "Epoch 14/20\n",
            "4455/4455 [==============================] - 103s 23ms/step - loss: 1.1747 - accuracy: 0.6269\n",
            "Epoch 15/20\n",
            "4455/4455 [==============================] - 103s 23ms/step - loss: 1.1691 - accuracy: 0.6289\n",
            "Epoch 16/20\n",
            "4455/4455 [==============================] - 103s 23ms/step - loss: 1.1655 - accuracy: 0.6294\n",
            "Epoch 17/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.1615 - accuracy: 0.6302\n",
            "Epoch 18/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.1588 - accuracy: 0.6312\n",
            "Epoch 19/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.1545 - accuracy: 0.6327\n",
            "Epoch 20/20\n",
            "4455/4455 [==============================] - 104s 23ms/step - loss: 1.1552 - accuracy: 0.6316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7ae2195310>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates the sequence similar to above methods. Gets the generated string using the model.\n",
        "def predict_next_n_chars(pattern, n):\n",
        "    for i in range(n):\n",
        "      x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "      prediction = model1.predict(x, verbose=0)\n",
        "      print (int_to_char[numpy.argmax(prediction)], end = '')   #get next char index.\n",
        "      seq_in = [int_to_char[value] for value in pattern]\n",
        "      pattern.append(numpy.argmax(prediction))\n",
        "      pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "id": "sUo1y1aJamdl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#picks a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "input_str = ''.join([int_to_char[value] for value in pattern])\n",
        "print (\"Seed -\",  input_str, sep = '\\n\\n')\n",
        "print (\"\\nGenerated string -\\n\")\n",
        "\n",
        "predict_next_n_chars(pattern, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtSiMqi1kQMM",
        "outputId": "d3015ef1-429d-4ebf-dc15-25a32748a13b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed -\n",
            "\n",
            "drove there in a taxi.  mr. philip ridgeway was there before us and looked somewhat surprised to see\n",
            "\n",
            "Generated string -\n",
            "\n",
            " him the story of the case of the case of the case"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = \"The boy laughed at the fright he had caused. This time, the villagers left angrily. The third day, as the boy went up\\\n",
        " the small hill, he suddenly saw a wolf attacking his sheep. He cried as hard as he could, “Wolf! Wolf! Wolf!”, but not \\\n",
        " a single villager came to help him. The villagers thought that he was trying to fool them again and did not come to rescue \\\n",
        " him or his sheep.\""
      ],
      "metadata": {
        "id": "KZt_WKamamgq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uses the first 100 characters from given input_str as input to generate next 200 characters. \n",
        "input_str = input_str.lower()\n",
        "input_string = ''\n",
        "for each in input_str:\n",
        "  if each in chars:\n",
        "    if (len (input_string)<100):\n",
        "      input_string += each"
      ],
      "metadata": {
        "id": "Qd_sW7oobE5N"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = []\n",
        "pattern.append([char_to_int[char] for char in input_string])"
      ],
      "metadata": {
        "id": "4V5YU-uDbGfm"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Seed -\",  input_str, sep = '\\n\\n')\n",
        "print (\"\\nGenerated string -\\n\")\n",
        "predict_next_n_chars(pattern[0], 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJqImBw4bHpc",
        "outputId": "cf3c6c87-568c-4bc6-9b74-9392dd1dbb25"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed -\n",
            "\n",
            "drove there in a taxi.  mr. philip ridgeway was there before us and looked somewhat surprised to see\n",
            "\n",
            "Generated string -\n",
            "\n",
            "i should have been a man of the station of the cas"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = []\n",
        "pattern.append([char_to_int[char] for char in input_string])"
      ],
      "metadata": {
        "id": "fxc2n1jRk1Rg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Seed -\",  input_str, sep = '\\n\\n')\n",
        "print (\"\\nGenerated string -\\n\")\n",
        "predict_next_n_chars(pattern[0], 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiodLb6AbZ4a",
        "outputId": "deefb0fc-2dab-49ce-c11e-b1931bbc8991"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed -\n",
            "\n",
            "the boy laughed at the fright he had caused. this time, the villagers left angrily. the third day, as the boy went up the small hill, he suddenly saw a wolf attacking his sheep. he cried as hard as he could, “wolf! wolf! wolf!”, but not  a single villager came to help him. the villagers thought that he was trying to fool them again and did not come to rescue  him or his sheep.\n",
            "\n",
            "Generated string -\n",
            "\n",
            "i should have been a man of the station of the cas"
          ]
        }
      ]
    }
  ]
}