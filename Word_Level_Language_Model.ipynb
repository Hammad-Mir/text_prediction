{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Language_Model_01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MtWJSxmlJlQk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import string\n",
        "import numpy as np\n",
        "from pickle import dump\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, GRU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path to text file\n",
        "doc_path = \"drive/MyDrive/Newcastle University/Deep Learning/Data/61262-0.txt\""
      ],
      "metadata": {
        "id": "F_uDTiDVkho9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function used to plot the curves for loss and accuracy:\n",
        "def plot_curves(history):\n",
        "\n",
        "  # Plotting the loss curve:\n",
        "  plt.subplot()\n",
        "  plt.title('Cross Entropy')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  # Plotting the training loss (blue):\n",
        "  plt.plot(history.history['loss'], color='red', label='train')\n",
        "  plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "  # Legend for the plot:\n",
        "  plt.legend(['loss', 'acc'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svWdMnwj5Soj",
        "outputId": "b34926ae-9c89-4101-b318-8228fc17af9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "  # open the file as read only\n",
        "  file = open(filename, 'r')\n",
        "  # read all text\n",
        "  text = file.read()\n",
        "  # close the file\n",
        "  file.close()\n",
        "  return text"
      ],
      "metadata": {
        "id": "ryEnw6pikhuN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert a document into clean tokens\n",
        "def clean_doc(doc):\n",
        "\t# replacing '--' with a space ' '\n",
        "\tdoc = doc.replace('--', ' ')\n",
        "\t# splitting into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# removing punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# removing non-alphabetic tokens\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# converting to lower case\n",
        "\ttokens = [word.lower() for word in tokens]\n",
        "\treturn tokens"
      ],
      "metadata": {
        "id": "9Jn1v4AkkhxD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()"
      ],
      "metadata": {
        "id": "0akjRWGPkh0e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the document\n",
        "doc = load_doc(doc_path)\n",
        "print(doc[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFBw-mlykh2i",
        "outputId": "de1eccb5-dd22-43d9-f5d0-63ed317a33d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg EBook of Poirot Investigates, by Agatha Christie\n",
            "\n",
            "This eBook is for the use of anyone anywhere in the United States and most\n",
            "other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever.  You may copy it, give it away or re-use it under the terms of\n",
            "the Proje\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting total length of the document\n",
        "print('total length of the document:', len(doc), 'characters')\n",
        "\n",
        "# getting a list of all the unique words in the document\n",
        "characters = sorted(list(set(doc)))\n",
        "print('total unique characters:', len(characters))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-L9e3Vbpxk0",
        "outputId": "ea821185-d38e-4e75-b058-ae87df4d118d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total length of the document: 316568 characters\n",
            "total unique characters: 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[1500:1666])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ql1T6kMsyOl",
        "outputId": "a7a6330d-06aa-4dc5-8f01-7bc957553299"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prime Minister\n",
            "\n",
            "  IX The Disappearance of Mr. Davenheim\n",
            "\n",
            "  X The Adventure of the Italian Nobleman\n",
            "\n",
            "  XI The Case of the Missing Will\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  POIROT INVESTIGATES\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[1666:2000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJg-EnRyzEIz",
        "outputId": "9bf4938a-60dc-41a7-dc50-498b6c1b75f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POIROT INVESTIGATES\n",
            "\n",
            "\n",
            "  I\n",
            "\n",
            "\n",
            "  The Adventure of “The Western Star”\n",
            "\n",
            "I was standing at the window of Poirot’s rooms looking out idly on\n",
            "the street below.\n",
            "\n",
            "“That’s queer,” I ejaculated suddenly beneath my breath.\n",
            "\n",
            "“What is, _mon ami_?” asked Poirot placidly, from the depths of\n",
            "his comfortable chair.\n",
            "\n",
            "“Deduce, Poirot, from the following\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doc[-20000:-18970])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvXxUbfexjAh",
        "outputId": "7d98f01b-3c50-4f58-ec65-374ce92e9971"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " He foresaw every step that a searcher\n",
            "would take—that I, miserable imbecile, took. He gets two will-forms,\n",
            "makes the servants sign twice, then sallies out with his will\n",
            "written on the inside of a dirty envelope and a fountain-pen\n",
            "containing his little ink mixture. On some excuse he gets the\n",
            "confectioner and his wife to sign their names under his own\n",
            "signature, then he ties it to the key of his desk and chuckles to\n",
            "himself. If his niece sees through his little ruse, she will have\n",
            "justified her choice of life and elaborate education, and be\n",
            "thoroughly welcome to his money.”\n",
            "\n",
            "“She didn’t see through it, did she?” I said slowly. “It seems\n",
            "rather unfair. The old man really won.”\n",
            "\n",
            "“But no, Hastings. It is _your_ wits that go astray. Miss Marsh\n",
            "proved the astuteness of her wits and the value of the higher\n",
            "education for women by at once putting the matter in _my_ hands.\n",
            "Always employ the expert. She has amply proved her right to the\n",
            "money.”\n",
            "\n",
            "I wonder—I very much wonder—what old Andrew Marsh would have\n",
            "thought!\n",
            "\n",
            "\n",
            "  THE END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing disclaimer and text not part of the novel contents\n",
        "doc = doc[1666:-18970]"
      ],
      "metadata": {
        "id": "4QMX-FK5ywRl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('First 100 characters\\n\\n', doc[:1000])\n",
        "print('\\n\\nLast 1000 characters\\n\\n', doc[-1000:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFfBYt_qzra-",
        "outputId": "459ea2ae-0647-454e-b4d2-a5a7f74085ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 100 characters\n",
            "\n",
            " POIROT INVESTIGATES\n",
            "\n",
            "\n",
            "  I\n",
            "\n",
            "\n",
            "  The Adventure of “The Western Star”\n",
            "\n",
            "I was standing at the window of Poirot’s rooms looking out idly on\n",
            "the street below.\n",
            "\n",
            "“That’s queer,” I ejaculated suddenly beneath my breath.\n",
            "\n",
            "“What is, _mon ami_?” asked Poirot placidly, from the depths of\n",
            "his comfortable chair.\n",
            "\n",
            "“Deduce, Poirot, from the following facts! Here is a young lady,\n",
            "richly dressed—fashionable hat, magnificent furs. She is coming\n",
            "along slowly, looking up at the houses as she goes. Unknown to her,\n",
            "she is being shadowed by three men and a middle-aged woman. They\n",
            "have just been joined by an errand boy who points after the girl,\n",
            "gesticulating as he does so. What drama is this being played? Is\n",
            "the girl a crook, and are the shadowers detectives preparing to\n",
            "arrest her? Or are _they_ the scoundrels, and are they plotting to\n",
            "attack an innocent victim? What does the great detective say?”\n",
            "\n",
            "“The great detective, _mon ami_, chooses, as ever, the simplest\n",
            "course. He rises to see for himself.” And my frie\n",
            "\n",
            "\n",
            "Last 1000 characters\n",
            "\n",
            " searcher\n",
            "would take—that I, miserable imbecile, took. He gets two will-forms,\n",
            "makes the servants sign twice, then sallies out with his will\n",
            "written on the inside of a dirty envelope and a fountain-pen\n",
            "containing his little ink mixture. On some excuse he gets the\n",
            "confectioner and his wife to sign their names under his own\n",
            "signature, then he ties it to the key of his desk and chuckles to\n",
            "himself. If his niece sees through his little ruse, she will have\n",
            "justified her choice of life and elaborate education, and be\n",
            "thoroughly welcome to his money.”\n",
            "\n",
            "“She didn’t see through it, did she?” I said slowly. “It seems\n",
            "rather unfair. The old man really won.”\n",
            "\n",
            "“But no, Hastings. It is _your_ wits that go astray. Miss Marsh\n",
            "proved the astuteness of her wits and the value of the higher\n",
            "education for women by at once putting the matter in _my_ hands.\n",
            "Always employ the expert. She has amply proved her right to the\n",
            "money.”\n",
            "\n",
            "I wonder—I very much wonder—what old Andrew Marsh would have\n",
            "thought!\n",
            "\n",
            "\n",
            "  THE END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning document\n",
        "tokens = clean_doc(doc)\n",
        "print(tokens[:200])\n",
        "print('Total Tokens: %d' % len(tokens))\n",
        "print('Unique Tokens: %d' % len(set(tokens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KNvhkApo115",
        "outputId": "5b58e45b-91de-497b-ebed-4fa8a0552c70"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['poirot', 'investigates', 'i', 'the', 'adventure', 'of', 'western', 'i', 'was', 'standing', 'at', 'the', 'window', 'of', 'rooms', 'looking', 'out', 'idly', 'on', 'the', 'street', 'below', 'i', 'ejaculated', 'suddenly', 'beneath', 'my', 'breath', 'is', 'mon', 'asked', 'poirot', 'placidly', 'from', 'the', 'depths', 'of', 'his', 'comfortable', 'chair', 'poirot', 'from', 'the', 'following', 'facts', 'here', 'is', 'a', 'young', 'lady', 'richly', 'hat', 'magnificent', 'furs', 'she', 'is', 'coming', 'along', 'slowly', 'looking', 'up', 'at', 'the', 'houses', 'as', 'she', 'goes', 'unknown', 'to', 'her', 'she', 'is', 'being', 'shadowed', 'by', 'three', 'men', 'and', 'a', 'middleaged', 'woman', 'they', 'have', 'just', 'been', 'joined', 'by', 'an', 'errand', 'boy', 'who', 'points', 'after', 'the', 'girl', 'gesticulating', 'as', 'he', 'does', 'so', 'what', 'drama', 'is', 'this', 'being', 'played', 'is', 'the', 'girl', 'a', 'crook', 'and', 'are', 'the', 'shadowers', 'detectives', 'preparing', 'to', 'arrest', 'her', 'or', 'are', 'they', 'the', 'scoundrels', 'and', 'are', 'they', 'plotting', 'to', 'attack', 'an', 'innocent', 'victim', 'what', 'does', 'the', 'great', 'detective', 'great', 'detective', 'mon', 'ami', 'chooses', 'as', 'ever', 'the', 'simplest', 'course', 'he', 'rises', 'to', 'see', 'for', 'and', 'my', 'friend', 'joined', 'me', 'at', 'the', 'window', 'in', 'a', 'minute', 'he', 'gave', 'vent', 'to', 'an', 'amused', 'chuckle', 'usual', 'your', 'facts', 'are', 'tinged', 'with', 'your', 'incurable', 'romanticism', 'that', 'is', 'miss', 'mary', 'marvell', 'the', 'film', 'star', 'she', 'is', 'being', 'followed', 'by', 'a', 'bevy', 'of', 'admirers', 'who', 'have']\n",
            "Total Tokens: 47909\n",
            "Unique Tokens: 5595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# organizing into sequences of tokens\n",
        "length = 30 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = tokens[i-length:i]\n",
        "\t# convert into a line\n",
        "\tline = ' '.join(seq)\n",
        "\t# store\n",
        "\tsequences.append(line)\n",
        "print('Total Sequences: %d' % len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4eqDd2Ro14g",
        "outputId": "02bcb7e5-6971-48e3-ab3d-9578d55a6c5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences: 47878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences)\n",
        "#sys.getsizeof(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAj406-vwIHQ",
        "outputId": "de00fa7e-eb4f-4346-feee-d81d6704777a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47878"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOR-utTP1aZ8",
        "outputId": "9e338440-7c9a-4e5d-d3c2-f4faed809b6e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47878,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YyqPl3F4WhYz",
        "outputId": "04ba174d-68ce-465f-806a-f21f669cd491"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'investigates i the adventure of western i was standing at the window of rooms looking out idly on the street below i ejaculated suddenly beneath my breath is mon asked poirot'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save sequences to file\n",
        "out_filename = 'drive/MyDrive/Newcastle University/Deep Learning/Data/piorot_investigates.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "metadata": {
        "id": "8pu39gxKo16-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# loading the sequence from file\n",
        "doc = load_doc(out_filename)\n",
        "lines = doc.split('\\n')"
      ],
      "metadata": {
        "id": "u_HsGAWU09fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(sequences)\n",
        "sequences = tokenizer.texts_to_sequences(sequences)"
      ],
      "metadata": {
        "id": "ev-SosDWo19d"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "NpNNP1X9-cv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUz9i-Wio1_y",
        "outputId": "a54bc42e-6cea-47fd-feb9-e16ed85b7853"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5596"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate into input and output\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0RPpB-Ro2EF",
        "outputId": "7c3d36e6-03d4-40e5-9e86-80587462ca90"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n",
        "\n",
        "Model 1 only has one LSTM layer followed by a classification layer"
      ],
      "metadata": {
        "id": "pofsgRuo5uNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(vocab_size, 30, input_length=seq_length))\n",
        "model_1.add(LSTM(128))\n",
        "model_1.add(Dense(vocab_size, activation='softmax'))"
      ],
      "metadata": {
        "id": "qzPNtaeLo2G8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDFf6yXj3yxe",
        "outputId": "7088a004-83fd-4e08-ecbd-bebab8318433"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 30, 30)            167880    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 128)               81408     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5596)              721884    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 971,172\n",
            "Trainable params: 971,172\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate=0.002)\n",
        "adam = keras.optimizers.Adam(0.02)\n",
        "nadam = keras.optimizers.Nadam(learning_rate=0.002)"
      ],
      "metadata": {
        "id": "gRVEAoVG3_VH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model_1.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# fit model\n",
        "history = model_1.fit(X, y, batch_size=128, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aiAdxUHo2KW",
        "outputId": "4ef3ba02-60df-4b48-c9c3-1cbb3cd4bba1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "337/337 [==============================] - 6s 11ms/step - loss: 6.6676 - accuracy: 0.0627 - val_loss: 6.6060 - val_accuracy: 0.0620\n",
            "Epoch 2/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 6.2456 - accuracy: 0.0732 - val_loss: 6.5532 - val_accuracy: 0.0796\n",
            "Epoch 3/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 6.0302 - accuracy: 0.0845 - val_loss: 6.5147 - val_accuracy: 0.0871\n",
            "Epoch 4/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 5.8409 - accuracy: 0.0956 - val_loss: 6.4820 - val_accuracy: 0.0911\n",
            "Epoch 5/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 5.6678 - accuracy: 0.1039 - val_loss: 6.4931 - val_accuracy: 0.0936\n",
            "Epoch 6/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 5.5048 - accuracy: 0.1114 - val_loss: 6.5019 - val_accuracy: 0.0998\n",
            "Epoch 7/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 5.3414 - accuracy: 0.1217 - val_loss: 6.5323 - val_accuracy: 0.1023\n",
            "Epoch 8/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 5.1800 - accuracy: 0.1302 - val_loss: 6.5719 - val_accuracy: 0.1090\n",
            "Epoch 9/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 5.0227 - accuracy: 0.1388 - val_loss: 6.6169 - val_accuracy: 0.1159\n",
            "Epoch 10/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 4.8691 - accuracy: 0.1492 - val_loss: 6.6871 - val_accuracy: 0.1151\n",
            "Epoch 11/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 4.7188 - accuracy: 0.1592 - val_loss: 6.7460 - val_accuracy: 0.1159\n",
            "Epoch 12/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 4.5726 - accuracy: 0.1688 - val_loss: 6.8066 - val_accuracy: 0.1163\n",
            "Epoch 13/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 4.4280 - accuracy: 0.1777 - val_loss: 6.8972 - val_accuracy: 0.1092\n",
            "Epoch 14/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 4.2876 - accuracy: 0.1870 - val_loss: 6.9651 - val_accuracy: 0.1134\n",
            "Epoch 15/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 4.1493 - accuracy: 0.1991 - val_loss: 7.0601 - val_accuracy: 0.1119\n",
            "Epoch 16/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 4.0143 - accuracy: 0.2129 - val_loss: 7.1467 - val_accuracy: 0.1061\n",
            "Epoch 17/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.8804 - accuracy: 0.2291 - val_loss: 7.2391 - val_accuracy: 0.1107\n",
            "Epoch 18/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.7531 - accuracy: 0.2453 - val_loss: 7.3268 - val_accuracy: 0.1094\n",
            "Epoch 19/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.6304 - accuracy: 0.2638 - val_loss: 7.4497 - val_accuracy: 0.1099\n",
            "Epoch 20/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.5141 - accuracy: 0.2811 - val_loss: 7.5318 - val_accuracy: 0.1117\n",
            "Epoch 21/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.4049 - accuracy: 0.2967 - val_loss: 7.6321 - val_accuracy: 0.1063\n",
            "Epoch 22/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.3011 - accuracy: 0.3134 - val_loss: 7.7572 - val_accuracy: 0.1071\n",
            "Epoch 23/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.2029 - accuracy: 0.3282 - val_loss: 7.8631 - val_accuracy: 0.1036\n",
            "Epoch 24/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.1180 - accuracy: 0.3423 - val_loss: 7.9731 - val_accuracy: 0.1034\n",
            "Epoch 25/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 3.0239 - accuracy: 0.3600 - val_loss: 8.0849 - val_accuracy: 0.0975\n",
            "Epoch 26/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.9411 - accuracy: 0.3737 - val_loss: 8.2035 - val_accuracy: 0.0936\n",
            "Epoch 27/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.8621 - accuracy: 0.3880 - val_loss: 8.3208 - val_accuracy: 0.0973\n",
            "Epoch 28/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.7887 - accuracy: 0.4020 - val_loss: 8.4290 - val_accuracy: 0.0998\n",
            "Epoch 29/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.7159 - accuracy: 0.4137 - val_loss: 8.5436 - val_accuracy: 0.0965\n",
            "Epoch 30/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.6474 - accuracy: 0.4289 - val_loss: 8.6676 - val_accuracy: 0.0940\n",
            "Epoch 31/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.5812 - accuracy: 0.4410 - val_loss: 8.7696 - val_accuracy: 0.0911\n",
            "Epoch 32/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.5157 - accuracy: 0.4538 - val_loss: 8.8931 - val_accuracy: 0.0919\n",
            "Epoch 33/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.4563 - accuracy: 0.4658 - val_loss: 9.0089 - val_accuracy: 0.0919\n",
            "Epoch 34/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.3960 - accuracy: 0.4755 - val_loss: 9.1201 - val_accuracy: 0.0927\n",
            "Epoch 35/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.3400 - accuracy: 0.4882 - val_loss: 9.2133 - val_accuracy: 0.0904\n",
            "Epoch 36/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.2837 - accuracy: 0.4993 - val_loss: 9.3313 - val_accuracy: 0.0904\n",
            "Epoch 37/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.2296 - accuracy: 0.5091 - val_loss: 9.4381 - val_accuracy: 0.0888\n",
            "Epoch 38/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.1781 - accuracy: 0.5183 - val_loss: 9.5773 - val_accuracy: 0.0909\n",
            "Epoch 39/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.1284 - accuracy: 0.5296 - val_loss: 9.6668 - val_accuracy: 0.0875\n",
            "Epoch 40/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.0767 - accuracy: 0.5424 - val_loss: 9.7865 - val_accuracy: 0.0871\n",
            "Epoch 41/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 2.0301 - accuracy: 0.5503 - val_loss: 9.8760 - val_accuracy: 0.0852\n",
            "Epoch 42/100\n",
            "337/337 [==============================] - 4s 11ms/step - loss: 1.9841 - accuracy: 0.5604 - val_loss: 9.9665 - val_accuracy: 0.0869\n",
            "Epoch 43/100\n",
            "337/337 [==============================] - 4s 11ms/step - loss: 1.9387 - accuracy: 0.5709 - val_loss: 10.0882 - val_accuracy: 0.0848\n",
            "Epoch 44/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.8951 - accuracy: 0.5804 - val_loss: 10.1936 - val_accuracy: 0.0829\n",
            "Epoch 45/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.8534 - accuracy: 0.5884 - val_loss: 10.2930 - val_accuracy: 0.0831\n",
            "Epoch 46/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.8115 - accuracy: 0.5976 - val_loss: 10.3842 - val_accuracy: 0.0846\n",
            "Epoch 47/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.7709 - accuracy: 0.6068 - val_loss: 10.4833 - val_accuracy: 0.0815\n",
            "Epoch 48/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.7305 - accuracy: 0.6147 - val_loss: 10.5991 - val_accuracy: 0.0796\n",
            "Epoch 49/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.6903 - accuracy: 0.6238 - val_loss: 10.6944 - val_accuracy: 0.0806\n",
            "Epoch 50/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.6559 - accuracy: 0.6325 - val_loss: 10.7853 - val_accuracy: 0.0796\n",
            "Epoch 51/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.6191 - accuracy: 0.6397 - val_loss: 10.8956 - val_accuracy: 0.0802\n",
            "Epoch 52/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.5812 - accuracy: 0.6487 - val_loss: 10.9738 - val_accuracy: 0.0789\n",
            "Epoch 53/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.5488 - accuracy: 0.6580 - val_loss: 11.0745 - val_accuracy: 0.0779\n",
            "Epoch 54/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.5139 - accuracy: 0.6631 - val_loss: 11.1883 - val_accuracy: 0.0756\n",
            "Epoch 55/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.4815 - accuracy: 0.6703 - val_loss: 11.2816 - val_accuracy: 0.0758\n",
            "Epoch 56/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.4478 - accuracy: 0.6772 - val_loss: 11.3766 - val_accuracy: 0.0802\n",
            "Epoch 57/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.4161 - accuracy: 0.6857 - val_loss: 11.4677 - val_accuracy: 0.0739\n",
            "Epoch 58/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.3853 - accuracy: 0.6937 - val_loss: 11.5537 - val_accuracy: 0.0760\n",
            "Epoch 59/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.3576 - accuracy: 0.6991 - val_loss: 11.6415 - val_accuracy: 0.0760\n",
            "Epoch 60/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.3440 - accuracy: 0.7013 - val_loss: 11.7420 - val_accuracy: 0.0750\n",
            "Epoch 61/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.3081 - accuracy: 0.7107 - val_loss: 11.8357 - val_accuracy: 0.0764\n",
            "Epoch 62/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.2722 - accuracy: 0.7177 - val_loss: 11.9287 - val_accuracy: 0.0754\n",
            "Epoch 63/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.2438 - accuracy: 0.7241 - val_loss: 12.0276 - val_accuracy: 0.0735\n",
            "Epoch 64/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.2174 - accuracy: 0.7307 - val_loss: 12.1180 - val_accuracy: 0.0714\n",
            "Epoch 65/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.1908 - accuracy: 0.7377 - val_loss: 12.2021 - val_accuracy: 0.0708\n",
            "Epoch 66/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.1697 - accuracy: 0.7426 - val_loss: 12.3224 - val_accuracy: 0.0716\n",
            "Epoch 67/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.1422 - accuracy: 0.7482 - val_loss: 12.3925 - val_accuracy: 0.0714\n",
            "Epoch 68/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.1175 - accuracy: 0.7550 - val_loss: 12.4841 - val_accuracy: 0.0718\n",
            "Epoch 69/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.0956 - accuracy: 0.7595 - val_loss: 12.5695 - val_accuracy: 0.0741\n",
            "Epoch 70/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 1.0714 - accuracy: 0.7649 - val_loss: 12.6828 - val_accuracy: 0.0727\n",
            "Epoch 71/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 1.0516 - accuracy: 0.7702 - val_loss: 12.7450 - val_accuracy: 0.0706\n",
            "Epoch 72/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 1.0319 - accuracy: 0.7741 - val_loss: 12.8460 - val_accuracy: 0.0693\n",
            "Epoch 73/100\n",
            "337/337 [==============================] - 4s 11ms/step - loss: 1.0130 - accuracy: 0.7793 - val_loss: 12.9172 - val_accuracy: 0.0687\n",
            "Epoch 74/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.9908 - accuracy: 0.7839 - val_loss: 13.0199 - val_accuracy: 0.0693\n",
            "Epoch 75/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 0.9687 - accuracy: 0.7888 - val_loss: 13.0975 - val_accuracy: 0.0675\n",
            "Epoch 76/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 0.9483 - accuracy: 0.7948 - val_loss: 13.1948 - val_accuracy: 0.0662\n",
            "Epoch 77/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 0.9277 - accuracy: 0.7989 - val_loss: 13.2783 - val_accuracy: 0.0700\n",
            "Epoch 78/100\n",
            "337/337 [==============================] - 3s 9ms/step - loss: 0.9111 - accuracy: 0.8017 - val_loss: 13.3498 - val_accuracy: 0.0695\n",
            "Epoch 79/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.8936 - accuracy: 0.8081 - val_loss: 13.4649 - val_accuracy: 0.0660\n",
            "Epoch 80/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.8783 - accuracy: 0.8105 - val_loss: 13.5231 - val_accuracy: 0.0643\n",
            "Epoch 81/100\n",
            "337/337 [==============================] - 4s 12ms/step - loss: 0.8642 - accuracy: 0.8122 - val_loss: 13.6278 - val_accuracy: 0.0629\n",
            "Epoch 82/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.8447 - accuracy: 0.8190 - val_loss: 13.6679 - val_accuracy: 0.0652\n",
            "Epoch 83/100\n",
            "337/337 [==============================] - 4s 11ms/step - loss: 0.8294 - accuracy: 0.8216 - val_loss: 13.7617 - val_accuracy: 0.0645\n",
            "Epoch 84/100\n",
            "337/337 [==============================] - 4s 11ms/step - loss: 0.8138 - accuracy: 0.8252 - val_loss: 13.8286 - val_accuracy: 0.0687\n",
            "Epoch 85/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7972 - accuracy: 0.8282 - val_loss: 13.9372 - val_accuracy: 0.0664\n",
            "Epoch 86/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7856 - accuracy: 0.8314 - val_loss: 14.0008 - val_accuracy: 0.0652\n",
            "Epoch 87/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7670 - accuracy: 0.8359 - val_loss: 14.0853 - val_accuracy: 0.0616\n",
            "Epoch 88/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7575 - accuracy: 0.8369 - val_loss: 14.1825 - val_accuracy: 0.0627\n",
            "Epoch 89/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7427 - accuracy: 0.8415 - val_loss: 14.2173 - val_accuracy: 0.0614\n",
            "Epoch 90/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7266 - accuracy: 0.8446 - val_loss: 14.2906 - val_accuracy: 0.0624\n",
            "Epoch 91/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7171 - accuracy: 0.8469 - val_loss: 14.3834 - val_accuracy: 0.0629\n",
            "Epoch 92/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.7033 - accuracy: 0.8492 - val_loss: 14.4288 - val_accuracy: 0.0641\n",
            "Epoch 93/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.6932 - accuracy: 0.8536 - val_loss: 14.5265 - val_accuracy: 0.0616\n",
            "Epoch 94/100\n",
            "337/337 [==============================] - 4s 12ms/step - loss: 0.6833 - accuracy: 0.8540 - val_loss: 14.6021 - val_accuracy: 0.0637\n",
            "Epoch 95/100\n",
            "337/337 [==============================] - 5s 14ms/step - loss: 0.6626 - accuracy: 0.8589 - val_loss: 14.6976 - val_accuracy: 0.0608\n",
            "Epoch 96/100\n",
            "337/337 [==============================] - 5s 14ms/step - loss: 0.6509 - accuracy: 0.8623 - val_loss: 14.7555 - val_accuracy: 0.0614\n",
            "Epoch 97/100\n",
            "337/337 [==============================] - 4s 11ms/step - loss: 0.6406 - accuracy: 0.8654 - val_loss: 14.8304 - val_accuracy: 0.0650\n",
            "Epoch 98/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.6380 - accuracy: 0.8665 - val_loss: 14.9259 - val_accuracy: 0.0608\n",
            "Epoch 99/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.6369 - accuracy: 0.8629 - val_loss: 14.9559 - val_accuracy: 0.0643\n",
            "Epoch 100/100\n",
            "337/337 [==============================] - 3s 10ms/step - loss: 0.6186 - accuracy: 0.8693 - val_loss: 15.0437 - val_accuracy: 0.0637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to file\n",
        "model_1.save('drive/MyDrive/Newcastle University/Deep Learning/Models/Language_Model_1.1.h5')"
      ],
      "metadata": {
        "id": "dm0O0JSZp-sv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(history)"
      ],
      "metadata": {
        "id": "7toGWI9s-nS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2\n",
        "\n",
        "Model 2 only has 2 LSTM layers followed by a dense and a classification layer"
      ],
      "metadata": {
        "id": "S2PyPkay8CQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_2 = Sequential()\n",
        "model_2.add(Embedding(vocab_size, 30, input_length=seq_length))\n",
        "model_2.add(LSTM(128, return_sequences=True))\n",
        "model_2.add(LSTM(256))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(vocab_size, activation='softmax'))"
      ],
      "metadata": {
        "id": "lZqFVY215qE4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a396dcac-5419-4250-982d-f44177695cf4",
        "id": "rui_uaNl5qFD"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 30, 30)            167880    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 30, 128)           81408     \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 256)               394240    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5596)              565196    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,234,424\n",
            "Trainable params: 1,234,424\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate=0.002)\n",
        "adam = keras.optimizers.Adam(0.002)\n",
        "nadam = keras.optimizers.Nadam(learning_rate=0.002)"
      ],
      "metadata": {
        "id": "cfRln8Hu5qFE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# fit model\n",
        "history = model_2.fit(X, y, batch_size=128, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bad056-ec4a-470b-b9d2-b32bdb45f2e2",
        "id": "4fjvAT8I5qFE"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 8s 14ms/step - loss: 6.6589 - accuracy: 0.0599\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 6.2281 - accuracy: 0.0692\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 6.0314 - accuracy: 0.0772\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 5.8747 - accuracy: 0.0854\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 5.7580 - accuracy: 0.0943\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 5.6381 - accuracy: 0.0994\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 5.5413 - accuracy: 0.1039\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 5.4553 - accuracy: 0.1090\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 5.3745 - accuracy: 0.1119\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 5.3261 - accuracy: 0.1151\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 5.2439 - accuracy: 0.1176\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 5.1743 - accuracy: 0.1211\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 5.1180 - accuracy: 0.1241\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 5.0658 - accuracy: 0.1278\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.9991 - accuracy: 0.1313\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.9208 - accuracy: 0.1363\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.8529 - accuracy: 0.1395\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.7828 - accuracy: 0.1430\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.7138 - accuracy: 0.1442\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.6499 - accuracy: 0.1486\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.5837 - accuracy: 0.1526\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.5227 - accuracy: 0.1542\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.4572 - accuracy: 0.1567\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.3946 - accuracy: 0.1616\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.3425 - accuracy: 0.1655\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.2824 - accuracy: 0.1690\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.2247 - accuracy: 0.1729\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.1727 - accuracy: 0.1784\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.1207 - accuracy: 0.1830\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.0714 - accuracy: 0.1878\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 4.0232 - accuracy: 0.1907\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.9688 - accuracy: 0.1975\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.9192 - accuracy: 0.2036\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.8723 - accuracy: 0.2081\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.8240 - accuracy: 0.2123\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.7777 - accuracy: 0.2176\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.7319 - accuracy: 0.2255\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.6896 - accuracy: 0.2301\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.6435 - accuracy: 0.2372\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.6032 - accuracy: 0.2416\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.5596 - accuracy: 0.2468\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.5106 - accuracy: 0.2530\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.4669 - accuracy: 0.2600\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.4148 - accuracy: 0.2668\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.3778 - accuracy: 0.2728\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.3312 - accuracy: 0.2823\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.2949 - accuracy: 0.2857\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.2570 - accuracy: 0.2923\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.2169 - accuracy: 0.2972\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.1710 - accuracy: 0.3039\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.1254 - accuracy: 0.3129\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.0876 - accuracy: 0.3174\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.0493 - accuracy: 0.3252\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 3.0104 - accuracy: 0.3315\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.9678 - accuracy: 0.3385\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.9467 - accuracy: 0.3419\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.8937 - accuracy: 0.3524\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.8569 - accuracy: 0.3574\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.8179 - accuracy: 0.3652\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.7710 - accuracy: 0.3757\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.7435 - accuracy: 0.3781\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.6989 - accuracy: 0.3859\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.6681 - accuracy: 0.3918\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.6364 - accuracy: 0.3961\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.5953 - accuracy: 0.4026\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.5547 - accuracy: 0.4139\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.5121 - accuracy: 0.4206\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.4915 - accuracy: 0.4250\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.4478 - accuracy: 0.4321\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.4117 - accuracy: 0.4388\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.3830 - accuracy: 0.4449\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.3542 - accuracy: 0.4495\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.3149 - accuracy: 0.4580\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.2929 - accuracy: 0.4610\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.2589 - accuracy: 0.4686\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.2196 - accuracy: 0.4783\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.1834 - accuracy: 0.4827\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.1385 - accuracy: 0.4935\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.1151 - accuracy: 0.4972\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.0921 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.0612 - accuracy: 0.5055\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.0379 - accuracy: 0.5134\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 1.9930 - accuracy: 0.5201\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.9602 - accuracy: 0.5292\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.9727 - accuracy: 0.5231\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.9046 - accuracy: 0.5405\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.8853 - accuracy: 0.5423\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.8312 - accuracy: 0.5557\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.8156 - accuracy: 0.5577\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.8073 - accuracy: 0.5576\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.7631 - accuracy: 0.5687\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.7606 - accuracy: 0.5678\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.7324 - accuracy: 0.5734\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.6981 - accuracy: 0.5804\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.6662 - accuracy: 0.5890\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.6226 - accuracy: 0.6011\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.6415 - accuracy: 0.5936\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.5907 - accuracy: 0.6057\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.5729 - accuracy: 0.6087\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.5398 - accuracy: 0.6148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to file\n",
        "model_2.save('drive/MyDrive/Newcastle University/Deep Learning/Models/Language_Model_2.h5')"
      ],
      "metadata": {
        "id": "d8JOnyOk5qFF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FKk_78upDRb4",
        "outputId": "856eaa6d-bc08-452f-a376-7c1cd353ff17"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3\n",
        "\n",
        "Model 3 only has 1 GRU layers followed by a dense and a classification layer"
      ],
      "metadata": {
        "id": "WU38OGLZA-ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_3 = Sequential()\n",
        "model_3.add(Embedding(vocab_size, 30, input_length=seq_length))\n",
        "model_3.add(GRU(256))\n",
        "model_3.add(Dense(vocab_size, activation='softmax'))"
      ],
      "metadata": {
        "id": "1VEpyZ7TA-pt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8d47d2-41f9-4d58-ff2c-5f8be35f292e",
        "id": "Blr3puavA-pu"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 30, 30)            167880    \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 256)               221184    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5596)              1438172   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,827,236\n",
            "Trainable params: 1,827,236\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate=0.002)\n",
        "adam = keras.optimizers.Adam(0.002)\n",
        "nadam = keras.optimizers.Nadam(learning_rate=0.002)"
      ],
      "metadata": {
        "id": "aOT5l-mXA-pv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model_3.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# fit model\n",
        "history = model_3.fit(X, y, batch_size=128, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8b74b5-f3da-4795-8d4b-41440bb245ff",
        "id": "MwkE0E92A-pv"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 5s 9ms/step - loss: 6.7761 - accuracy: 0.0649\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 6.0134 - accuracy: 0.0895\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 5.6122 - accuracy: 0.1158\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 5.2079 - accuracy: 0.1357\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 4.7143 - accuracy: 0.1572\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 4.1319 - accuracy: 0.2009\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 3.5124 - accuracy: 0.2834\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.9684 - accuracy: 0.3715\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.5400 - accuracy: 0.4474\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.1955 - accuracy: 0.5137\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 1.9167 - accuracy: 0.5689\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.6774 - accuracy: 0.6186\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4895 - accuracy: 0.6595\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.3464 - accuracy: 0.6888\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2149 - accuracy: 0.7183\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.1139 - accuracy: 0.7386\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.0017 - accuracy: 0.7643\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.9346 - accuracy: 0.7765\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8957 - accuracy: 0.7831\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8146 - accuracy: 0.8028\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7594 - accuracy: 0.8141\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7452 - accuracy: 0.8121\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7066 - accuracy: 0.8229\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6670 - accuracy: 0.8314\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6710 - accuracy: 0.8242\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6874 - accuracy: 0.8196\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6426 - accuracy: 0.8300\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6816 - accuracy: 0.8154\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6671 - accuracy: 0.8146\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6339 - accuracy: 0.8264\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5622 - accuracy: 0.8482\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5861 - accuracy: 0.8374\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.5689 - accuracy: 0.8411\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6066 - accuracy: 0.8283\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6633 - accuracy: 0.8078\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6058 - accuracy: 0.8271\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7151 - accuracy: 0.7913\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6039 - accuracy: 0.8256\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6155 - accuracy: 0.8210\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6337 - accuracy: 0.8146\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7121 - accuracy: 0.7899\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7441 - accuracy: 0.7801\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6668 - accuracy: 0.8046\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6298 - accuracy: 0.8125\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6379 - accuracy: 0.8111\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6905 - accuracy: 0.7947\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.6723 - accuracy: 0.8002\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.7337 - accuracy: 0.7821\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7700 - accuracy: 0.7716\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7038 - accuracy: 0.7905\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7195 - accuracy: 0.7869\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7358 - accuracy: 0.7810\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7517 - accuracy: 0.7764\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7657 - accuracy: 0.7707\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.7846 - accuracy: 0.7668\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8359 - accuracy: 0.7545\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8944 - accuracy: 0.7378\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0385 - accuracy: 0.7020\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9760 - accuracy: 0.7174\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9801 - accuracy: 0.7149\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9560 - accuracy: 0.7229\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9105 - accuracy: 0.7330\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.8670 - accuracy: 0.7457\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.9768 - accuracy: 0.7168\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0301 - accuracy: 0.7048\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0731 - accuracy: 0.6934\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.0922 - accuracy: 0.6903\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1885 - accuracy: 0.6649\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1313 - accuracy: 0.6816\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1850 - accuracy: 0.6684\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1256 - accuracy: 0.6823\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.1350 - accuracy: 0.6810\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2420 - accuracy: 0.6566\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2839 - accuracy: 0.6472\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2200 - accuracy: 0.6597\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.2068 - accuracy: 0.6622\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3211 - accuracy: 0.6397\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4240 - accuracy: 0.6170\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3283 - accuracy: 0.6366\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3194 - accuracy: 0.6405\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3604 - accuracy: 0.6298\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.5376 - accuracy: 0.5925\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4765 - accuracy: 0.6035\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4305 - accuracy: 0.6133\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.3770 - accuracy: 0.6269\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4648 - accuracy: 0.6057\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.4902 - accuracy: 0.6021\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.5917 - accuracy: 0.5811\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 1.8033 - accuracy: 0.5416\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.0479 - accuracy: 0.5004\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.4452 - accuracy: 0.4385\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.4819 - accuracy: 0.4354\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3207 - accuracy: 0.4563\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.1263 - accuracy: 0.4860\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.0435 - accuracy: 0.4964\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.1052 - accuracy: 0.4867\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.2096 - accuracy: 0.4680\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.2577 - accuracy: 0.4629\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 2.3203 - accuracy: 0.4521\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 3.0188 - accuracy: 0.3607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to file\n",
        "model_3.save('drive/MyDrive/Newcastle University/Deep Learning/Models/Language_Model_3.h5')"
      ],
      "metadata": {
        "id": "ltIkBtZUA-pw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "nw8bkBZ0A4gW",
        "outputId": "6a736bca-2fdb-4e87-f9b1-33d233fc1102"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4\n",
        "\n",
        "Model 4 has 2 GRU layers followed by a dense and a classification layer"
      ],
      "metadata": {
        "id": "-SZOXBXTBAdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model_4 = Sequential()\n",
        "model_4.add(Embedding(vocab_size, 30, input_length=seq_length))\n",
        "model_4.add(GRU(128, return_sequences=True))\n",
        "model_4.add(GRU(256))\n",
        "model_4.add(Dense(128, activation='relu'))\n",
        "model_4.add(Dense(vocab_size, activation='softmax'))"
      ],
      "metadata": {
        "id": "5M04B7ETBAdu"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57dcb5a-e681-4048-8cb7-eea53d3418f8",
        "id": "Jts71tYHBAdu"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 30, 30)            167880    \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 30, 128)           61440     \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 256)               296448    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 5596)              721884    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,548\n",
            "Trainable params: 1,280,548\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate=0.002)\n",
        "adam = keras.optimizers.Adam(0.002)\n",
        "nadam = keras.optimizers.Nadam(learning_rate=0.002)"
      ],
      "metadata": {
        "id": "EC1cZrrwBAdu"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model_4.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# fit model\n",
        "history = model_4.fit(X, y, batch_size=128, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef809c9-0c18-40dc-befe-a708765cf348",
        "id": "l3O2CnFgBAdu"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 7s 12ms/step - loss: 6.6510 - accuracy: 0.0582\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 6.2235 - accuracy: 0.0717\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 5.9905 - accuracy: 0.0820\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 5.7659 - accuracy: 0.0957\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 5.5524 - accuracy: 0.1100\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 5.3725 - accuracy: 0.1209\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 5.1929 - accuracy: 0.1323\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 5.0221 - accuracy: 0.1428\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 4.8552 - accuracy: 0.1537\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 4.6919 - accuracy: 0.1662\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 4.5244 - accuracy: 0.1796\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 4.3669 - accuracy: 0.1909\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 4.1909 - accuracy: 0.2049\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 4.0171 - accuracy: 0.2203\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 3.8500 - accuracy: 0.2354\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 3.6964 - accuracy: 0.2520\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 3.5110 - accuracy: 0.2734\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 3.3403 - accuracy: 0.2932\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 3.1886 - accuracy: 0.3163\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 3.0185 - accuracy: 0.3400\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.8550 - accuracy: 0.3681\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.7239 - accuracy: 0.3869\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.5746 - accuracy: 0.4132\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.4268 - accuracy: 0.4388\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.2988 - accuracy: 0.4621\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.1776 - accuracy: 0.4828\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.0432 - accuracy: 0.5112\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.9518 - accuracy: 0.5298\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.8931 - accuracy: 0.5371\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.7248 - accuracy: 0.5740\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.6584 - accuracy: 0.5855\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.5287 - accuracy: 0.6155\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.4788 - accuracy: 0.6210\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.4246 - accuracy: 0.6344\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.3262 - accuracy: 0.6554\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.2534 - accuracy: 0.6720\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.1767 - accuracy: 0.6871\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.1007 - accuracy: 0.7049\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.0782 - accuracy: 0.7107\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.0101 - accuracy: 0.7240\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 1.0028 - accuracy: 0.7261\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.9746 - accuracy: 0.7303\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.9225 - accuracy: 0.7429\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.8409 - accuracy: 0.7636\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.8385 - accuracy: 0.7659\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.8615 - accuracy: 0.7574\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.8891 - accuracy: 0.7467\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7699 - accuracy: 0.7778\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7348 - accuracy: 0.7890\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6897 - accuracy: 0.8023\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7513 - accuracy: 0.7819\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7667 - accuracy: 0.7781\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6517 - accuracy: 0.8090\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6569 - accuracy: 0.8064\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5904 - accuracy: 0.8242\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6151 - accuracy: 0.8180\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6111 - accuracy: 0.8203\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7412 - accuracy: 0.7816\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6827 - accuracy: 0.7999\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.7095 - accuracy: 0.7903\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5964 - accuracy: 0.8234\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5067 - accuracy: 0.8466\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5482 - accuracy: 0.8363\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5225 - accuracy: 0.8422\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5506 - accuracy: 0.8335\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5883 - accuracy: 0.8253\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6052 - accuracy: 0.8215\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5640 - accuracy: 0.8309\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5240 - accuracy: 0.8420\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5645 - accuracy: 0.8331\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5205 - accuracy: 0.8424\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4953 - accuracy: 0.8503\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6344 - accuracy: 0.8116\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6736 - accuracy: 0.8039\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5256 - accuracy: 0.8397\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4431 - accuracy: 0.8646\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4509 - accuracy: 0.8638\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5359 - accuracy: 0.8402\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5389 - accuracy: 0.8378\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5378 - accuracy: 0.8399\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5523 - accuracy: 0.8355\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5417 - accuracy: 0.8366\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5805 - accuracy: 0.8275\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4871 - accuracy: 0.8531\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4526 - accuracy: 0.8602\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4354 - accuracy: 0.8689\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5259 - accuracy: 0.8441\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.6065 - accuracy: 0.8221\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5490 - accuracy: 0.8390\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4812 - accuracy: 0.8556\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4814 - accuracy: 0.8546\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5174 - accuracy: 0.8462\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5291 - accuracy: 0.8438\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4675 - accuracy: 0.8589\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5036 - accuracy: 0.8496\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5194 - accuracy: 0.8474\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5228 - accuracy: 0.8440\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4839 - accuracy: 0.8549\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5222 - accuracy: 0.8470\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.5971 - accuracy: 0.8264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to file\n",
        "model_4.save('drive/MyDrive/Newcastle University/Deep Learning/Models/Language_Model_4.h5')"
      ],
      "metadata": {
        "id": "qiECUJqjBAdv"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "4-122kbpA4kU",
        "outputId": "39902292-4a9a-4e86-d240-c63fe71d42f9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Un3fWxnrA4nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C641z2ldA4pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q1Fwbi81A4sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-gjDfz22A4uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "np88gN7fA4wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J1uNTCjOA407"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AyGvus9iA43j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0BCWG-jAA458"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dCR7QZqCo2Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t8BRTfbUo2SU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}